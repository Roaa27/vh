{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roaa27/vh/blob/main/QAWT_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZAohAlZ0bpz"
      },
      "source": [
        "Step 1: Install and Import Libraries  \n",
        "I installed Hugging Face Transformers, Datasets, and Evaluate libraries.  \n",
        "These are used to load pre-trained models, manage datasets, and calculate evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5SAtDfVy3tC",
        "outputId": "6c67c315-a46c-42c1-b608-f5d1aa24ff28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "✅ Libraries installed and imported successfully!\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwmVrgz40dyz"
      },
      "source": [
        "Step 2: Load Dataset (SQuAD v1.1)  \n",
        "I loaded the Stanford Question Answering Dataset (SQuAD v1.1), which contains passages, questions, and answers.  \n",
        "The dataset is split into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BOW-eijzgtn",
        "outputId": "cba9f97b-6a9a-4346-f844-1ddfe43ba2c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset loaded successfully!\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 87599\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 10570\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"squad\")\n",
        "print(\"✅ Dataset loaded successfully!\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28eLk6Fg0gs4"
      },
      "source": [
        "Step 3: Load Pre-trained Model and Tokenizer  \n",
        "I used the pre-trained DistilBERT model fine-tuned on SQuAD.  \n",
        "The tokenizer converts text into numerical tokens, and the model predicts answer spans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl3FzGi3zoIn",
        "outputId": "7ffc19d8-43a4-467b-9cfc-d8ddc75ab0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model and tokenizer loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "model_name = \"distilbert-base-uncased-distilled-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "print(\"✅ Model and tokenizer loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paRoAOp_0i6N"
      },
      "source": [
        "Step 4: Create Question Answering Pipeline  \n",
        "I created a Hugging Face pipeline for question answering.  \n",
        "By providing a question and a context passage, the model extracts the correct answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZLJFrwgztix",
        "outputId": "d5497937-d23c-4789-aa21-bcde25500ff0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Which NFL team represented the AFC at Super Bowl 50?\n",
            "Answer: Denver Broncos\n"
          ]
        }
      ],
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "context = dataset[\"validation\"][0][\"context\"]\n",
        "question = dataset[\"validation\"][0][\"question\"]\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", result[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJNdPko-0lgb"
      },
      "source": [
        "Step 5: Evaluate the Model  \n",
        "I evaluated the model on a subset of 200 validation samples.  \n",
        "The evaluation metrics include Exact Match (EM) and F1 Score, which measure how well the predicted answers match the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP8Uf3QSz4_a",
        "outputId": "ed533703-46ca-4676-f331-d10411b32125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Evaluation Results: {'exact_match': 85.0, 'f1': 89.3917748917749}\n"
          ]
        }
      ],
      "source": [
        "metric = evaluate.load(\"squad\")\n",
        "\n",
        "n_samples = 200\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "    context = dataset[\"validation\"][i][\"context\"]\n",
        "    question = dataset[\"validation\"][i][\"question\"]\n",
        "    answers = dataset[\"validation\"][i][\"answers\"]\n",
        "\n",
        "    result = qa_pipeline(question=question, context=context)\n",
        "\n",
        "    predictions.append({\n",
        "        \"id\": dataset[\"validation\"][i][\"id\"],\n",
        "        \"prediction_text\": result[\"answer\"]\n",
        "    })\n",
        "    references.append({\n",
        "        \"id\": dataset[\"validation\"][i][\"id\"],\n",
        "        \"answers\": answers\n",
        "    })\n",
        "\n",
        "scores = metric.compute(predictions=predictions, references=references)\n",
        "print(\"✅ Evaluation Results:\", scores)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGlNOhpj0nho"
      },
      "source": [
        "Step 6 (Bonus): Try Another Model  \n",
        "As a bonus step, I tested another model (RoBERTa fine-tuned on SQuAD).  \n",
        "This allowed me to compare the performance of different transformer-based models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "bf438db13f0347de8fdcd54d5de0ddcb",
            "13307a6cfd0748dfa669659c75e1b17f",
            "163d42db808f46bbae19c7d0f97deb7e",
            "1e8a3be1156d4959858e3fc9f2de0375",
            "9490525333164e47995ee00b9c2812d1",
            "57063df717294543a516b2703c5a3df0",
            "1536897a6b624ad0b88f34a8be51382d",
            "6a3e63fa2b7c4e4fb513fe069335974f",
            "305abb20a93b456c894893bf67edd157",
            "374327f53f5e4026878ea2ee6392d1ef",
            "bca9b42fbfc04e3b8ec1fbf58699d057",
            "9d35c411cdf94ff3b9bf1688164d90b9",
            "9bf10a6aceb44cd2887dda570819bc17",
            "3f17ebea25ac4b8f9fcb1d0761695fa1",
            "6711af61d470482cb8930af796a554bf",
            "d6e5bf4f451547599e1ada897357ec75",
            "fe87054d88d748538c3b14c2b11389e5",
            "d90c5e11d9e54b49b42e3453e5dcf5a6",
            "4bcf450092db414c9e32f88bb065cc30",
            "211fa249bb814de5a488869841a017df",
            "06b70961f5d444b4afc3428a51cfd7dd",
            "2c6e9971306140adba3d5b39daa8b775",
            "2e34d91018a64d2e877c21452fd3ef79",
            "ef242d793eee4f4289b83ebee0ce6987",
            "5510bf7ec36a4dec9d58560027408590",
            "7f8f4798dc134ff1a40a6f8db137eacd",
            "a3f7b0ea7f3b4c52af3e5150daaeec56",
            "2aa7e6598c504f5e939f86bc3a26c249",
            "eedc6d4c700e4bd883fac168cfac2380",
            "167e8708f293475dbd6fb96a04e31c89",
            "6499950b9e8742e0bd8b2df5acd23bde",
            "d87998152fa3449784fbdad56aa6a97c",
            "f26ca43a8de44247be4482b1aa285edc"
          ]
        },
        "id": "mR9e02fiz9Vz",
        "outputId": "ac5f7ba9-72eb-43eb-ee47-ec4f3ef2c232"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf438db13f0347de8fdcd54d5de0ddcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d35c411cdf94ff3b9bf1688164d90b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e34d91018a64d2e877c21452fd3ef79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bonus Test with RoBERTa:\n",
            "Question: Who was the first president of the United States?\n",
            "Answer: George Washington\n"
          ]
        }
      ],
      "source": [
        "alt_model = \"deepset/roberta-base-squad2\"\n",
        "qa_pipeline_alt = pipeline(\"question-answering\", model=alt_model, tokenizer=alt_model)\n",
        "\n",
        "sample_q = \"Who was the first president of the United States?\"\n",
        "sample_c = \"George Washington was the first president of the United States and served from 1789 to 1797.\"\n",
        "\n",
        "print(\"\\nBonus Test with RoBERTa:\")\n",
        "print(\"Question:\", sample_q)\n",
        "print(\"Answer:\", qa_pipeline_alt(question=sample_q, context=sample_c)[\"answer\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}